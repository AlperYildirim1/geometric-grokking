{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "mount_file_id": "1nDoRshnuELG1B2lN4KxsfZHIg96aRR3-",
      "authorship_tag": "ABX9TyOrQKrXeTFmrrBgoRTr0SmR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlperYildirim1/geometric-grokking/blob/main/Grokking_S5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import itertools\n",
        "from tqdm.auto import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "\n",
        "SAVE_DIR = '/content/drive/MyDrive/grokking_logs_s5'\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "# ==========================================\n",
        "# CONFIGURATION\n",
        "# ==========================================\n",
        "N_DEGREE = 5                            # S5 Symmetric Group\n",
        "GROUP_SIZE = math.factorial(N_DEGREE)   # 120 elements\n",
        "FRAC_TRAIN = 0.3\n",
        "D_MODEL = 128\n",
        "NUM_HEADS = 4\n",
        "MLP_DIM = 512\n",
        "LR = 4e-3\n",
        "WEIGHT_DECAY = 1.0\n",
        "EPOCHS = 60000                          # S5 usually takes slightly longer than Z_p\n",
        "LOG_EVERY = 200\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "SEED = 5\n",
        "\n",
        "# ==========================================\n",
        "# BULLETPROOF DETERMINISM\n",
        "# ==========================================\n",
        "def set_seed(seed):\n",
        "    \"\"\"Locks down all sources of randomness for 100% reproducibility.\"\"\"\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
        "\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.use_deterministic_algorithms(True, warn_only=True)\n",
        "\n",
        "# ==========================================\n",
        "# S5 DATASET GENERATION\n",
        "# ==========================================\n",
        "def generate_s5_elements():\n",
        "    \"\"\"Generates the 120 elements of S5 and their composition table.\"\"\"\n",
        "    elements = list(itertools.permutations(range(N_DEGREE)))\n",
        "    elem_to_id = {elem: i for i, elem in enumerate(elements)}\n",
        "    id_to_elem = {i: elem for i, elem in enumerate(elements)}\n",
        "    return elements, elem_to_id, id_to_elem\n",
        "\n",
        "def compose_s5(id1, id2, id_to_elem, elem_to_id):\n",
        "    \"\"\"Composes two permutations: applying p2 then p1.\"\"\"\n",
        "    p1 = id_to_elem[id1]\n",
        "    p2 = id_to_elem[id2]\n",
        "    p_out = tuple(p1[p2[i]] for i in range(N_DEGREE))\n",
        "    return elem_to_id[p_out]\n",
        "\n",
        "def make_s5_dataset(frac_train, seed=42):\n",
        "    set_seed(seed)\n",
        "    rng = random.Random(seed)\n",
        "\n",
        "    _, elem_to_id, id_to_elem = generate_s5_elements()\n",
        "\n",
        "    all_pairs = [(a, b) for a in range(GROUP_SIZE) for b in range(GROUP_SIZE)]\n",
        "    rng.shuffle(all_pairs)\n",
        "\n",
        "    n_train = int(len(all_pairs) * frac_train)\n",
        "\n",
        "    # x inputs: [elem_A, elem_B, OP_TOKEN]\n",
        "    op_token = GROUP_SIZE # The index 120 acts as the composition operator\n",
        "\n",
        "    # Generate Train\n",
        "    train_x = torch.tensor([[a, b, op_token] for a, b in all_pairs[:n_train]], dtype=torch.long)\n",
        "    train_y = torch.tensor([compose_s5(a, b, id_to_elem, elem_to_id) for a, b in all_pairs[:n_train]], dtype=torch.long)\n",
        "\n",
        "    # Generate Test\n",
        "    test_x = torch.tensor([[a, b, op_token] for a, b in all_pairs[n_train:]], dtype=torch.long)\n",
        "    test_y = torch.tensor([compose_s5(a, b, id_to_elem, elem_to_id) for a, b in all_pairs[n_train:]], dtype=torch.long)\n",
        "\n",
        "    return train_x, train_y, test_x, test_y\n",
        "\n",
        "# ==========================================\n",
        "# STANDARD & SPHERICAL TRANSFORMER\n",
        "# ==========================================\n",
        "class StandardTransformer(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model, num_heads, mlp_dim, normalize_hiddens=False):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.d_head = d_model // num_heads\n",
        "        self.normalize_hiddens = normalize_hiddens\n",
        "\n",
        "        self.tok_embed = nn.Embedding(vocab_size + 1, d_model) # +1 for OP_TOKEN\n",
        "        self.pos_embed = nn.Embedding(3, d_model)\n",
        "\n",
        "        self.W_Q = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.W_K = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.W_V = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.W_O = nn.Linear(d_model, d_model, bias=False)\n",
        "\n",
        "        self.mlp_in = nn.Linear(d_model, mlp_dim)\n",
        "        self.mlp_out = nn.Linear(mlp_dim, d_model)\n",
        "        self.unembed = nn.Linear(d_model, vocab_size, bias=False) # Unembed back to 120 S5 elements\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, L = x.shape\n",
        "        pos = torch.arange(L, device=x.device).unsqueeze(0)\n",
        "        h = self.tok_embed(x) + self.pos_embed(pos)\n",
        "\n",
        "        if self.normalize_hiddens: h = F.normalize(h, dim=-1)\n",
        "\n",
        "        Q = self.W_Q(h).view(B, L, self.num_heads, self.d_head).transpose(1, 2)\n",
        "        K = self.W_K(h).view(B, L, self.num_heads, self.d_head).transpose(1, 2)\n",
        "        V = self.W_V(h).view(B, L, self.num_heads, self.d_head).transpose(1, 2)\n",
        "\n",
        "        scores = (Q @ K.transpose(-2, -1)) / math.sqrt(self.d_head)\n",
        "        attn_out = self.W_O((F.softmax(scores, dim=-1) @ V).transpose(1, 2).contiguous().view(B, L, self.d_model))\n",
        "\n",
        "        h = h + attn_out\n",
        "        if self.normalize_hiddens: h = F.normalize(h, dim=-1)\n",
        "\n",
        "        h = h + self.mlp_out(F.relu(self.mlp_in(h)))\n",
        "        if self.normalize_hiddens: h = F.normalize(h, dim=-1)\n",
        "\n",
        "        return self.unembed(h[:, 2, :])\n",
        "\n",
        "# ==========================================\n",
        "# TRAINING LOGIC\n",
        "# ==========================================\n",
        "def train_model(model, name, train_x, train_y, test_x, test_y, epochs):\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY, betas=(0.9, 0.999))\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    train_x, train_y = train_x.to(DEVICE), train_y.to(DEVICE)\n",
        "    test_x, test_y = test_x.to(DEVICE), test_y.to(DEVICE)\n",
        "\n",
        "    grok_epoch = None\n",
        "    history = {'epochs': [], 'train_acc': [], 'test_acc': [], 'train_loss': [], 'test_loss': []}\n",
        "\n",
        "    pbar = tqdm(range(epochs), desc=f\"Training {name}\")\n",
        "\n",
        "    for epoch in pbar:\n",
        "        model.train()\n",
        "        logits = model(train_x)\n",
        "        loss = criterion(logits, train_y)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if epoch % LOG_EVERY == 0 or epoch == epochs - 1:\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                train_acc = (logits.argmax(-1) == train_y).float().mean().item()\n",
        "                test_logits = model(test_x)\n",
        "                test_loss = criterion(test_logits, test_y).item()\n",
        "                test_acc = (test_logits.argmax(-1) == test_y).float().mean().item()\n",
        "\n",
        "            history['epochs'].append(epoch)\n",
        "            history['train_acc'].append(train_acc)\n",
        "            history['test_acc'].append(test_acc)\n",
        "            history['train_loss'].append(loss.item())\n",
        "            history['test_loss'].append(test_loss)\n",
        "\n",
        "            pbar.set_postfix({\n",
        "                'tr_acc': f\"{train_acc:.3f}\",\n",
        "                'te_acc': f\"{test_acc:.3f}\"\n",
        "            })\n",
        "\n",
        "            if grok_epoch is None and test_acc > 0.95:\n",
        "                grok_epoch = epoch\n",
        "                tqdm.write(f\"\\n⚡ {name} generalized at epoch {epoch}! (test_acc={test_acc:.4f})\")\n",
        "\n",
        "    return {\"grok_epoch\": grok_epoch if grok_epoch else f\">{epochs}\", \"history\": history}\n",
        "\n",
        "# ==========================================\n",
        "# EXECUTION & PLOTTING (1x2 Grid)\n",
        "# ==========================================\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"=\" * 60)\n",
        "    print(\"S5 GROKKING TEST: The Non-Circular Baseline\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    tr_x, tr_y, te_x, te_y = make_s5_dataset(FRAC_TRAIN, seed=SEED)\n",
        "\n",
        "    models = []\n",
        "\n",
        "    # 1. Standard Model (Should Grok)\n",
        "    set_seed(SEED)\n",
        "    models.append((\"Standard\", StandardTransformer(GROUP_SIZE, D_MODEL, NUM_HEADS, MLP_DIM, False), EPOCHS))\n",
        "\n",
        "    # 2. Spherical Norm (Should Struggle/Fail)\n",
        "    set_seed(SEED)\n",
        "    models.append((\"Spherical Norm\", StandardTransformer(GROUP_SIZE, D_MODEL, NUM_HEADS, MLP_DIM, True), EPOCHS))\n",
        "\n",
        "    results = {}\n",
        "    for name, model, train_epochs in models:\n",
        "        model = model.to(DEVICE)\n",
        "        results[name] = train_model(model, name, tr_x, tr_y, te_x, te_y, train_epochs)\n",
        "\n",
        "        safe_name = name.replace(\" \", \"_\")\n",
        "        save_path = os.path.join(SAVE_DIR, f\"{safe_name}_S5_seed{SEED}.json\")\n",
        "        with open(save_path, \"w\") as f:\n",
        "            json.dump(results[name][\"history\"], f)\n",
        "\n",
        "    # --- PLOTTING 1x2 GRID ---\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(14, 5))\n",
        "    axs = axs.flatten()\n",
        "\n",
        "    for i, (name, res) in enumerate(results.items()):\n",
        "        hist = res[\"history\"]\n",
        "\n",
        "        axs[i].plot(hist[\"epochs\"], hist[\"train_acc\"], label=\"Train Acc\", color=\"#1f77b4\", linewidth=2.5)\n",
        "        axs[i].plot(hist[\"epochs\"], hist[\"test_acc\"], label=\"Test Acc\", color=\"#d62728\", linewidth=2.5)\n",
        "        axs[i].fill_between(hist[\"epochs\"], hist[\"train_acc\"], hist[\"test_acc\"], color='red', alpha=0.1)\n",
        "\n",
        "        title_text = f\"S5: {name} Transformer\\nGeneralized at: {res['grok_epoch']}\"\n",
        "        axs[i].set_title(title_text, fontsize=16, pad=10)\n",
        "        axs[i].set_xlabel(\"Epochs\", fontsize=14)\n",
        "        axs[i].set_ylabel(\"Accuracy\", fontsize=14)\n",
        "        axs[i].tick_params(axis='both', which='major', labelsize=12)\n",
        "        axs[i].grid(True, alpha=0.3)\n",
        "        axs[i].legend(loc=\"lower right\", fontsize=12)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plot_path = os.path.join(SAVE_DIR, f\"grokking_S5_1x2_grid_seed{SEED}.png\")\n",
        "    plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
        "    print(f\"✅ Saved S5 plot to: {plot_path}\")\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "tWDRCTaNPA7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob, json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "SAVE_DIR = '/content/drive/MyDrive/grokking_logs'\n",
        "model_names = [\"Standard\", \"Fourier_Init\", \"Spherical_Norm\"]\n",
        "\n",
        "results_data = []\n",
        "\n",
        "print(\"Analyzing grokking moments across all seeds...\\n\")\n",
        "\n",
        "for model in model_names:\n",
        "    files = glob.glob(f\"{SAVE_DIR}/{model}_seed*.json\")\n",
        "    if not files:\n",
        "        continue\n",
        "\n",
        "    grok_epochs = []\n",
        "    did_not_grok_count = 0\n",
        "\n",
        "    for f in files:\n",
        "        data = json.load(open(f))\n",
        "        test_accs = data[\"test_acc\"]\n",
        "        epochs = data[\"epochs\"]\n",
        "\n",
        "        # Find the first epoch where test_acc > 0.95\n",
        "        grok_epoch = None\n",
        "        for epoch, acc in zip(epochs, test_accs):\n",
        "            if acc > 0.95:\n",
        "                grok_epoch = epoch\n",
        "                break\n",
        "\n",
        "        if grok_epoch is not None:\n",
        "            grok_epochs.append(grok_epoch)\n",
        "        else:\n",
        "            did_not_grok_count += 1\n",
        "\n",
        "    if grok_epochs:\n",
        "        results_data.append({\n",
        "            \"Model\": model.replace(\"_\", \" \"),\n",
        "            \"Seeds Run\": len(files),\n",
        "            \"Successful Groks\": len(grok_epochs),\n",
        "            \"Earliest Grok\": np.min(grok_epochs),\n",
        "            \"Latest Grok\": np.max(grok_epochs),\n",
        "            \"Average Grok\": int(np.mean(grok_epochs)),\n",
        "            \"Std Dev\": int(np.std(grok_epochs))\n",
        "        })\n",
        "\n",
        "if results_data:\n",
        "    # Use Pandas to print a clean, paper-ready table\n",
        "    df = pd.DataFrame(results_data)\n",
        "    print(df.to_markdown(index=False))\n",
        "else:\n",
        "    print(\"No log files found yet. Make sure training has finished!\")"
      ],
      "metadata": {
        "id": "6Oa4oUsjhSxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "import torch\n",
        "import subprocess\n",
        "import datetime\n",
        "\n",
        "# Make sure the directory exists\n",
        "SAVE_DIR = '/content/drive/MyDrive/grokking_logs'\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "env_log_path = os.path.join(SAVE_DIR, \"environment_info.txt\")\n",
        "\n",
        "with open(env_log_path, \"w\") as f:\n",
        "    f.write(f\"--- Grokking Experiment Environment Log ---\\n\")\n",
        "    f.write(f\"Timestamp: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
        "\n",
        "    # 1. Python Version\n",
        "    f.write(\"=== Python Version ===\\n\")\n",
        "    f.write(sys.version + \"\\n\\n\")\n",
        "\n",
        "    # 2. PyTorch & GPU Info\n",
        "    f.write(\"=== PyTorch & CUDA ===\\n\")\n",
        "    f.write(f\"PyTorch Version: {torch.__version__}\\n\")\n",
        "    f.write(f\"CUDA Available: {torch.cuda.is_available()}\\n\")\n",
        "    if torch.cuda.is_available():\n",
        "        f.write(f\"CUDA Built-in Version: {torch.version.cuda}\\n\")\n",
        "        f.write(f\"cuDNN Version: {torch.backends.cudnn.version()}\\n\")\n",
        "        f.write(f\"GPU Model: {torch.cuda.get_device_name(0)}\\n\")\n",
        "    f.write(\"\\n\")\n",
        "\n",
        "    # 3. Full NVIDIA-SMI Output\n",
        "    f.write(\"=== NVIDIA-SMI ===\\n\")\n",
        "    try:\n",
        "        nvidia_smi = subprocess.check_output(\"nvidia-smi\", shell=True).decode()\n",
        "        f.write(nvidia_smi + \"\\n\")\n",
        "    except Exception as e:\n",
        "        f.write(f\"Could not retrieve nvidia-smi: {e}\\n\\n\")\n",
        "\n",
        "    # 4. Pip Freeze (All installed libraries)\n",
        "    f.write(\"=== Installed PIP Packages ===\\n\")\n",
        "    try:\n",
        "        pip_freeze = subprocess.check_output(\"pip freeze\", shell=True).decode()\n",
        "        f.write(pip_freeze + \"\\n\")\n",
        "    except Exception as e:\n",
        "        f.write(f\"Could not retrieve pip freeze: {e}\\n\")\n",
        "\n",
        "print(f\"✅ Environment successfully logged to: {env_log_path}\")"
      ],
      "metadata": {
        "id": "SiNdMfEpJwyv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}